{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, '/home/ning_a/Desktop/CAPTCHA/base_solver/base_solver_char')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import captcha_setting\n",
    "import my_dataset\n",
    "from captcha_cnn_model import CNN, Generator\n",
    "from torchvision.utils import save_image\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load GAN net.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:230: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, '/home/ning_a/Desktop/CAPTCHA/base_solver/base_solver_char')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import captcha_setting\n",
    "import my_dataset\n",
    "from captcha_cnn_model import CNN, Generator\n",
    "from torchvision.utils import save_image\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import copy\n",
    "import operator\n",
    "import torch.nn as nn\n",
    "import captcha_setting\n",
    "from matplotlib import cm\n",
    "class testdataset(Dataset):\n",
    "\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.train_image_file_paths = [os.path.join(folder, image_file) for image_file in os.listdir(folder)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_image_file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_root = self.train_image_file_paths[idx]\n",
    "        image_name = image_root.split(os.path.sep)[-1]\n",
    "        image = Image.open(image_root)\n",
    "        image = image.resize((160,60), Image.ANTIALIAS)\n",
    "        label = image_name\n",
    "        if('_' in image_name):\n",
    "            label = image_name.split('_')[0]\n",
    "        else:\n",
    "            label = image_name.split('.')[0]\n",
    "            \n",
    "        #label = ohe.encode(image_name.split('_')[0]) # 为了方便，在生成图片的时候，图片文件的命名格式 \"4个数字或者数字_时间戳.PNG\", 4个字母或者即是图片的验证码的值，字母大写,同时对该值做 one-hot 处理\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            #label = self.transform(label)\n",
    "        #label = ohe.encode(image_name.split('_')[0])\n",
    "        return image, label\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ColorJitter(),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "def get_loader():\n",
    "    img_path = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/rescator_data/\"\n",
    "    img_path2 = \"/home/ning_a/Desktop/CAPTCHA/base_GAN/train/\"\n",
    "    img_path3 = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/mania_data/\"\n",
    "    dataset = testdataset(img_path, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear((captcha_setting.IMAGE_WIDTH//8)*(captcha_setting.IMAGE_HEIGHT//8)*64, 1024),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU())\n",
    "        self.rfc = nn.Sequential(\n",
    "            nn.Linear(1024, 256),#captcha_setting.MAX_CAPTCHA*captcha_setting.ALL_CHAR_SET_LEN),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rfc2 = nn.Sequential(\n",
    "            nn.Linear(256, captcha_setting.MAX_CAPTCHA*captcha_setting.ALL_CHAR_SET_LEN),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        #print(out.shape)\n",
    "        out = self.rfc(out)\n",
    "        out = self.rfc2(out)\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        return out\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn = CNN()\n",
    "cnn.eval()\n",
    "cnn.load_state_dict(torch.load('model_digit.pkl'))\n",
    "cnn.to(device)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ColorJitter(),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataloader = get_loader()\n",
    "\n",
    "generator = Generator()\n",
    "generator.load_state_dict(torch.load('/home/ning_a/Desktop/CAPTCHA/base_solver/base_solver_char/7800.pkl'))\n",
    "generator.eval()\n",
    "print(\"load GAN net.\")\n",
    "\n",
    "img_path = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/rescator_data/\"\n",
    "img_path1 = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/rescator_me/\"\n",
    "img_path2 = \"/home/ning_a/Desktop/CAPTCHA/base_GAN/train/\"\n",
    "\n",
    "img = cv.imread(img_path+\"1627.png\")\n",
    "\n",
    "dim = (160, 60)\n",
    "#img = cv.resize(img, dim, interpolation=cv.INTER_CUBIC)\n",
    "#img = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# img.shape\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# img = torch.tensor(img)\n",
    "# img = img.float()\n",
    "# #print(img.type())\n",
    "# new_img = generator(img).data.cpu().numpy()\n",
    "# plt.imshow(new_img[0][0])\n",
    "# plt.show()\n",
    "# #print(img)\n",
    "label_target = \"\"\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, (imgs, label) in enumerate(dataloader):\n",
    "#     plt.imshow(imgs[0][0])\n",
    "#     plt.show()\n",
    "    total += 1\n",
    "#     if(i<10):\n",
    "#         continue\n",
    "#     print(label)\n",
    "    label_target = label\n",
    "    imgs = torch.tensor(imgs).float()\n",
    "    new_img = generator(imgs)\n",
    "    new_img2 = new_img.data.cpu().numpy()\n",
    "    target_img = new_img2[0][0]\n",
    "    target_img = target_img*255\n",
    "    cv.imwrite( \"temp.jpg\",target_img) \n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    img = cv.imread('temp.jpg')\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    threshold = 5  \n",
    "    img = np.array(img)\n",
    "    n_img = np.zeros((img.shape[0],img.shape[1]))\n",
    "    img_aft = cv.normalize(img, n_img, 0,255,cv.NORM_MINMAX)\n",
    "#     plt.imshow(img_aft)\n",
    "#     plt.show()\n",
    "    gray = cv.cvtColor(img_aft,cv.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "    ret, thresh_reverse = cv.threshold(gray,0,255,cv.THRESH_OTSU)\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    im2,contours,hierarchy = cv.findContours(thresh,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "    filter_containor = []\n",
    "    temp_img = copy.deepcopy(img)\n",
    "    cur_contours = []\n",
    "    #print(len(contours))\n",
    "    for i in contours:\n",
    "        #print(i)\n",
    "        x, y, w, h = cv.boundingRect(i)   \n",
    "        cur_contours.append([x, y, w, h])\n",
    "        #break\n",
    "    contours = sorted(cur_contours, key=operator.itemgetter(0))\n",
    "    #print(len(contours))\n",
    "    for i in range(0,len(contours)):  \n",
    "        x = contours[i][0]\n",
    "        y = contours[i][1]\n",
    "        w = contours[i][2] \n",
    "        h = contours[i][3]\n",
    "        #= cv.boundingRect(contours[i])   \n",
    "        newimage=thresh_reverse[y:y+h,x:x+w] # 先用y确定高，再用x确定宽\n",
    "        nrootdir=(\"cut_image/\")\n",
    "        if h<5 and w<5:\n",
    "            continue\n",
    "        color = [255, 255, 255]\n",
    "        top, bottom, left, right = [1]*4\n",
    "\n",
    "        newimage = cv.copyMakeBorder(newimage, top, bottom, left, right, cv.BORDER_CONSTANT, value=color)\n",
    "        #newimage = \n",
    "        newimage = cv.resize(newimage,(30, 60), interpolation = cv.INTER_CUBIC)\n",
    "        #filter_containor.append(newimage)\n",
    "\n",
    "        cv.rectangle(temp_img, (x,y), (x+w,y+h), (153,153,0), 1)\n",
    "        if not os.path.isdir(nrootdir):\n",
    "            os.makedirs(nrootdir)\n",
    "        cv.imwrite( nrootdir+str(i)+\".jpg\",newimage)\n",
    "        cv.imwrite( \"temp.jpg\",newimage) \n",
    "        filter_containor.append(Image.open(\"temp.jpg\"))\n",
    "#         print (x, y, w, h)\n",
    "    #print(filter_containor)\n",
    "#     plt.imshow(temp_img)\n",
    "#     plt.show()\n",
    "    #>>>>>>>>>>>>>>>>>>>>>\n",
    "    label_predicted = \"\"\n",
    "    filter_containor = []\n",
    "    for i in range(4):\n",
    "        cv.imwrite( \"temp.jpg\",img[:,i*40:i*40+40])\n",
    "        filter_containor.append(Image.open(\"temp.jpg\"))\n",
    "    for eachimg in filter_containor:\n",
    "        #print(eachimg)\n",
    "        fix_size = (30, 60)\n",
    "        eachimg = eachimg.resize(fix_size)\n",
    "        image = transform(eachimg).unsqueeze(0)\n",
    "#         plt.imshow(eachimg)\n",
    "#         plt.show()\n",
    "#         print(image.shape)\n",
    "        \n",
    "        image = torch.tensor(image, device=device).float()\n",
    "        image = Variable(image).to(device)\n",
    "        #print(image.shape)\n",
    "        #image, labels =  image.to(device), labels.to(device)\n",
    "        # vimage = generator(image)\n",
    "        predict_label = cnn(image)\n",
    "        #labels = labels.cpu()\n",
    "        predict_label = predict_label.cpu()\n",
    "        _, predicted = torch.max(predict_label, 1)\n",
    "#         print(captcha_setting.ALL_CHAR_SET[predicted])\n",
    "        label_predicted += captcha_setting.ALL_CHAR_SET[predicted]\n",
    "#     print(label_predicted)\n",
    "#     print(label[0])\n",
    "    if(label_predicted==label[0]):\n",
    "        correct += 1\n",
    "#     break\n",
    "print(correct/total)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
